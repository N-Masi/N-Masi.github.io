<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Nick Masi</title>
    <link href="css/bootstrap.css" rel="stylesheet"/>
    <link href="css/custom.css" rel="stylesheet"/>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.min.css">
  </head>
  <body>
    <!--Bootstrap js-->
    <script src="javascript/bootstrap.js" defer></script>
    <ul class="nav nav-pills justify-content-end">
        <li class="nav-item">
            <a class="nav-link" aria-current="page" href="index.html">Home</a>
        </li>
        <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle active" data-bs-toggle="dropdown" role="button" aria-expanded="false">Projects</a>
            <ul class="dropdown-menu">
                <li><a class="dropdown-item" href="coding.html">Coding</a></li>
                <li><a class="dropdown-item active" href="writing.html">Writing</a></li>
                <li><a class="dropdown-item" href="visual.html">Visual</a></li>
            </ul>
        </li>
    </ul>

    <main class="flex-shrink-0" role="main">
        <div class="container">
            <h1>Peer Reviewed</h1>

            <p class="writing">"Adapatable Artifical Intelligence." Azish Filabi, <b>Nick Masi</b>, Ellie Pavlick, Rico Picone. <em>Journal on AI Policy and Complex Systems</em> 9, no. 1 (Winter 2024). <a href="papers/adaptable_artificial_intelligence.pdf" target="_blank" style="color: inherit;"><i class="bi bi-file-earmark-text-fill"></i></a></p>
            <ul class="writing-list">
                <li>Abstract: As artificial intelligence (AI) permeates private, public, and corporate life, the safety and trustworthiness of systems it underlies become paramount. Nevertheless, this line of research is underemphasized and scattered. To address this failing, we introduce the term <em>adaptability</em>: the capacity of an AI system’s behavior to maintain helpfulness and harmlessness as societal understandings of these concepts evolve. The term unifies the field of trustworthy AI by encompassing a range of yet disparate techniques, and it is a necessary property to secure durable trust in AI systems. We outline a public research program, grounded in adaptability as a common framework, to compare and evaluate existing approaches that are often siloed and to promote the pursuit of novel methods in the field. The governance and relevant criteria for this program are described. Importantly, the program must be publicly operated so that public benefit is prioritized over financial motivations. We detail how market pressures have rendered private industry fundamentally incapable of developing AI systems that the public can trust.</li>
            </ul>

            <h1>Online</h1>

            <p class="writing">GPU Export Controls: Background and Recommendations <a href="https://medium.com/@nicholas_masi/gpu-export-controls-dont-work-a754c953f04d" target="_blank" style="color: inherit;"><i class="bi bi-file-earmark-text-fill"></i></a></p>

            <ul class="writing-list">
              <li>Export controls on graphical processing units (GPUs), the physical hardware underpinning advancements in artificial intelligence (AI), have been a key tool in the Biden administration’s foreign policy on AI. The underlying assumptions are (1) export controls of GPUs are effective; and (2) without access to GPUs, adversaries cannot develop and leverage AI. This article starts with a brief background on recent American export controls of integrated circuits (ICs) (Section 1) as well as the policy goals behind these (Section 2). An analysis then shows how both of the above assumptions are wrong (Sections 3 and 4, respectively), and that even if they weren’t, their success may have undesirable unintended consequences (Section 5).</li>
            </ul>
            <!-- <p class="writing">Municipal Broadband</p> -->
            <p class="writing">WBRU Album Review: RIP Human Art</p>
            <ul class="writing-list">
              <li>Literary review of EARTHGANG and Spillage Village's EP RIP Human Art</li>
            </ul>
        </div>
    </main>
  </body>
  <footer class="border-top">
    <p class="text-muted text-center">© 2024 Nick Masi</p>
  </footer>
</html>
